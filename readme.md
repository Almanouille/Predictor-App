# ðŸ“¦ Predictor-App

### ðŸ“š Project Structure

```text
project-root/
â”œâ”€â”€ app.py                     # Streamlit main app
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ predictor.py          # Model class 
â”‚   â”œâ”€â”€ trainer.py            # Training logic
â”‚   â”œâ”€â”€ feature_calculator.py # feature computation logic
â”‚   â””â”€â”€ saved_models/        # Trained model files 
â”œâ”€â”€ data/                            # Raw and processed data (from your ETL)
â”‚   â”œâ”€â”€ raw/                         # Raw JSON data from API
â”‚   â”‚   â”œâ”€â”€ fixtures_39_2023.json    # Example for league_id 39 season 2023
â”‚   â”‚   â”œâ”€â”€ standings_39_2023.json
â”‚   â”‚   â””â”€â”€ team_stats_1_39_2023.json
â”‚   â”œâ”€â”€ processed/                   # Cleaned CSV data (ML training ready)
â”‚   â”‚   â”œâ”€â”€ fixtures_cleaned_39_2023.csv
â”‚   â”‚   â”œâ”€â”€ standings_cleaned_39_2023.csv
â”‚   â”‚   â””â”€â”€ team_stats_cleaned_39_2023.csv
â”‚   â””â”€â”€ consolidated/                # Final ML-ready datasets
â”‚       â”œâ”€â”€ fixtures_consolidated_20240327_143022.csv
â”‚       â””â”€â”€ team_statistics_consolidated_20240327_143022.csv
â”œâ”€â”€ config.py                # Handles env vars
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py 
â”‚   â””â”€â”€ helpers.py            # Utility functions 
â”œâ”€â”€ tests/ 
â”‚   â”œâ”€â”€ test_models.py 
â”‚   â””â”€â”€ test_etl.py 
â”œâ”€â”€ etl.py                   # Data extraction, transform, and load 
â”œâ”€â”€ requirements.txt 
â”œâ”€â”€ Dockerfile               # To support ETL, training, and Streamlit UI
â”œâ”€â”€ docker-compose.yml       # For database + app
â”œâ”€â”€ .env.example             # Environment variables template
â””â”€â”€ README.md
```
### Run Steps
#### **Part I**:Setup Instructions
* Create a virtual environment using Python 3.8: `python3.8 -m venv venv`
* Activate the virtual environment: `source venv/bin/activate`
* Install dependencies: `pip install -r requirements.txt`

#### **Part II**: Load history match data
* Run `python etl.py`, it will store data in raw and processed folders

#### **Part III**: Modeling
* Train and save model: run `python -m models.trainer` 
* Update `SELECTED_FEATURES` value in config.py 
* Predict: `python -m models.predictor`

#### **Part IV**: Predict on an application streamlit
* Run: `streamlit run app.py`